{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.4.0\n",
      "Numpy version: 1.18.4\n",
      "Pytorch version: 1.6.0+cu101\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 0563a4467fa602feca92d91c7f47261868d171a1\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 3.1.0\n",
      "scikit-image version: 0.17.2\n",
      "Pillow version: 8.0.1\n",
      "Tensorboard version: 2.2.1\n",
      "gdown version: 3.12.2\n",
      "TorchVision version: 0.7.0+cu101\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.54.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.8.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torchsummary import summary\n",
    "import random\n",
    "import numpy as np\n",
    "import configparser\n",
    "import gc\n",
    "import math\n",
    "#from utils.training_torch_utils import BoxCrop, Dulicated, train, validation, Data_progressing, plot_loss_metric\n",
    "#import utils.config as config\n",
    "#from efficientnet_3d.model_3d import EfficientNet3D\n",
    "#from resnet_3d import resnet_3d\n",
    "#from ModelsGenesis import unet3d\n",
    "import sys\n",
    "sys.path.append(\"/tf/jacky831006/classification_torch/NAS-Lung/\") \n",
    "from models.cnn_res import *\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet, densenet ,SENet\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadNiftid,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    ToTensord,\n",
    "    Resized,\n",
    "    RandAffined,\n",
    "    Rand3DElasticd\n",
    ")\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngleLoss_predict(nn.Module):\n",
    "    def __init__(self, gamma=0):\n",
    "        super(AngleLoss_predict, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.it = 1\n",
    "        self.LambdaMin = 5.0\n",
    "        self.LambdaMax = 1500.0\n",
    "        self.lamb = 1500.0\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        cos_theta, phi_theta = input\n",
    "        target = target.view(-1, 1)  # size=(B,1)\n",
    "        index = cos_theta.data * 0.0  # size=(B, Classnum)\n",
    "        # index = index.scatter(1, target.data.view(-1, 1).long(), 1)\n",
    "        #index = index.byte()\n",
    "        index = index.bool()  \n",
    "        index = Variable(index)\n",
    "        # index = Variable(torch.randn(1,2)).byte()\n",
    "\n",
    "        self.lamb = max(self.LambdaMin, self.LambdaMax / (1 + 0.1 target* self.it))\n",
    "        output = cos_theta * 1.0  # size=(B,Classnum)\n",
    "        output1 = output.clone()\n",
    "        # output1[index1] = output[index] - cos_theta[index] * (1.0 + 0) / (1 + self.lamb)\n",
    "        # output1[index1] = output[index] + phi_theta[index] * (1.0 + 0) / (1 + self.lamb)\n",
    "        output[index] = output1[index]- cos_theta[index] * (1.0 + 0) / (1 + self.lamb)+ phi_theta[index] * (1.0 + 0) / (1 + self.lamb)\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testLoader, device):\n",
    "    pre_first = True\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0.0\n",
    "        metric_count = 0\n",
    "        for testdata in testLoader:\n",
    "            test_images, test_labels = testdata['image'].to(device), testdata['label'].to(device)\n",
    "            output = model(test_images)\n",
    "            if isinstance(output, tuple):\n",
    "                output = AngleLoss_predict()(output,test_labels)\n",
    "            # output 並非0-1之間 故進行轉換\n",
    "            pre = nn.functional.softmax(output,dim=1).cpu().detach().numpy()\n",
    "            # 比較output與label 對的話則返回 true 錯則 false\n",
    "            value = torch.eq(output.argmax(dim=1), test_labels)\n",
    "            metric_count += len(value)\n",
    "            num_correct += value.sum().item()\n",
    "            if pre_first:\n",
    "                pre_first = None\n",
    "                predict_values = pre\n",
    "            else:\n",
    "                predict_values = np.concatenate((predict_values,pre),axis=0)\n",
    "        metric = num_correct / metric_count\n",
    "        print(\"Test Accuracy: {}\".format(num_correct / metric_count))\n",
    "        return (predict_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvRes(32,[[64, 64, 64], [128, 128, 256], [256, 256, 256, 512]])\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-1.2158, -0.1602],\n",
      "        [-1.2669, -0.2861],\n",
      "        [-1.0327, -0.4320],\n",
      "        [-1.3313, -0.2058],\n",
      "        [-1.2232, -0.3826],\n",
      "        [-1.0999, -0.0213],\n",
      "        [-1.4132, -0.1492],\n",
      "        [-1.2426, -0.4877]], device='cuda:0', grad_fn=<MulBackward0>), tensor([[-81.3050, -80.8748],\n",
      "        [-83.4876, -83.0482],\n",
      "        [-75.8539, -75.5748],\n",
      "        [-78.9563, -78.4282],\n",
      "        [-81.8026, -81.4053],\n",
      "        [-82.0370, -81.6822],\n",
      "        [-84.9888, -84.4288],\n",
      "        [-81.4677, -81.0817]], device='cuda:0', grad_fn=<MulBackward0>))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\",0)\n",
    "inputs = torch.randn((8, 1, 32, 32, 32)).to(device)\n",
    "labels = torch.randn((1)).to(device)\n",
    "output = net(inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM(object):\n",
    "    \"\"\"\n",
    "    1: 网络不更新梯度,输入需要梯度更新\n",
    "    2: 使用目标类别的得分做反向传播\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, net, layer_name, device):\n",
    "        self.net = net\n",
    "        self.layer_name = layer_name\n",
    "        self.feature = None\n",
    "        self.gradient = None\n",
    "        self.device = device\n",
    "        self.net.eval()\n",
    "        self.handlers = []\n",
    "        # 將 feature與gradient 取出\n",
    "        self._register_hook()\n",
    "\n",
    "    def _get_features_hook(self, module, input, output):\n",
    "        self.feature = output\n",
    "        #print(\"feature shape:{}\".format(output.size()))\n",
    "\n",
    "    def _get_grads_hook(self, module, input_grad, output_grad):\n",
    "        \"\"\"\n",
    "        :param input_grad: tuple,  input_grad[0]: None\n",
    "                                   input_grad[1]: weight\n",
    "                                   input_grlabelsad[2]: bias\n",
    "        :param output_grad:tuple,  长度为1\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.gradient = output_grad[0]\n",
    "\n",
    "    def _register_hook(self):\n",
    "        for (name, module) in self.net.named_modules():\n",
    "            if name == self.layer_name:\n",
    "                #print(\"OK\")\n",
    "                self.handlers.append(module.register_forward_hook(self._get_features_hook))\n",
    "                self.handlers.append(module.register_backward_hook(self._get_grads_hook))\n",
    "            #else:\n",
    "                #print(\"Nothing to do\")\n",
    "\n",
    "    def remove_handlers(self):\n",
    "        for handle in self.handlers:\n",
    "            handle.remove()\n",
    "\n",
    "    def __call__(self, inputs, index_sel=None):\n",
    "        \"\"\"\n",
    "        :param inputs: {\"image\": [C,H,W], \"height\": height, \"width\": width}\n",
    "        :param index_sel: 第几个边框\n",
    "        :return:  a list of each batch heatmap\n",
    "        \"\"\"\n",
    "        # 將 feature與gradient 取出\n",
    "        #self._register_hook()\n",
    "        # forward\n",
    "        # with torch.no_grad():\n",
    "\n",
    "        self.net.zero_grad()\n",
    "        output = self.net(inputs) # [1,num_classes]\n",
    "        heatmap_list = []\n",
    "        print(f\"output shape: {output[0].shape}\")\n",
    "        #print(output)\n",
    "        for i in range(output[0].shape[0]):\n",
    "            if  index_sel == None:\n",
    "                index = np.argmax(output[0].data[i,:].cpu().data.numpy())\n",
    "                print(f\"predict:{index}\")  \n",
    "            else:\n",
    "                index = index_sel\n",
    "            # backward\n",
    "            target = output[0][i][index]\n",
    "            print(target)\n",
    "            target.backward(retain_graph=True)\n",
    "            print(self.gradient)\n",
    "            gradient = self.gradient[i].cpu().detach().data.numpy()  # [C,H,W,D]\n",
    "            weight = np.mean(gradient, axis=(1, 2, 3))  # [C]\n",
    "\n",
    "            feature = self.feature[i].cpu().detach().data.numpy()  # [C,H,W,D]\n",
    "            \n",
    "            # np.newaxis 增加維度的方法\n",
    "            cam = feature * weight[:, np.newaxis, np.newaxis, np.newaxis]  # [C,H,W,D] feature map 與 weight相乘\n",
    "            cam = np.sum(cam, axis=0)  # [H,W,D] \n",
    "            cam = np.maximum(cam, 0)  # ReLU\n",
    "            heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "            heatmap = resize(heatmap,inputs.shape[2:5])\n",
    "            heatmap_list.append(heatmap)\n",
    "\n",
    "        return heatmap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM_2(object):\n",
    "    \"\"\"\n",
    "    1: 网络不更新梯度,输入需要梯度更新\n",
    "    2: 使用目标类别的得分做反向传播\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, net, layer_name, device):\n",
    "        self.net = net\n",
    "        self.layer_name = layer_name\n",
    "        self.feature = None\n",
    "        self.gradient = None\n",
    "        self.device = device\n",
    "        self.net.eval()\n",
    "        self.handlers = []\n",
    "        # 將 feature與gradient 取出\n",
    "        self._register_hook()\n",
    "\n",
    "    def _get_features_hook(self, module, input, output):\n",
    "        self.feature = output\n",
    "        print(self.feature)\n",
    "        print(\"feature shape:{}\".format(output.size()))\n",
    "\n",
    "    def _get_grads_hook(self, module, input_grad, output_grad):\n",
    "        \"\"\"\n",
    "        :param input_grad: tuple,  input_grad[0]: None\n",
    "                                   input_grad[1]: weight\n",
    "                                   input_grad[2]: bias\n",
    "        :param output_grad:tuple,  长度为1\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.gradient = output_grad[0]\n",
    "        print(self.gradient)\n",
    "\n",
    "    def _register_hook(self):\n",
    "        for (name, module) in self.net.named_modules():\n",
    "            if name == self.layer_name:\n",
    "                #print(\"OK\")\n",
    "                self.handlers.append(module.register_forward_hook(self._get_features_hook))\n",
    "                self.handlers.append(module.register_backward_hook(self._get_grads_hook))\n",
    "            #else:\n",
    "                #print(\"Nothing to do\")\n",
    "\n",
    "    def remove_handlers(self):\n",
    "        for handle in self.handlers:\n",
    "            handle.remove()\n",
    "\n",
    "    def __call__(self, inputs, labels, index_sel=None):\n",
    "        \"\"\"\n",
    "        :param inputs: {\"image\": [C,H,W], \"height\": height, \"width\": width}\n",
    "        :param index_sel: 第几个边框\n",
    "        :return:  a list of each batch heatmap\n",
    "        \"\"\"\n",
    "        # 將 feature與gradient 取出\n",
    "        #self._register_hook()\n",
    "        # forward\n",
    "        # with torch.no_grad():\n",
    "\n",
    "        self.net.zero_grad()\n",
    "        output = self.net(inputs) # [1,num_classes]\n",
    "        \n",
    "        print(output[0].grad_fn)\n",
    "        if isinstance(output, tuple):\n",
    "            #output = AngleLoss_predict()(output,test_labels)\n",
    "            output2 = output[0]\n",
    "            print(output2)\n",
    "            print(output2.grad_fn)\n",
    "            output = Variable(output)\n",
    "        heatmap_list = []\n",
    "        #print(f\"output shape: {output.shape}\")\n",
    "        \n",
    "        for i in range(output.shape[0]):\n",
    "            if  index_sel == None:\n",
    "                index = np.argmax(output[i,:].cpu().data.numpy())\n",
    "                print(f\"predict:{index}\")  \n",
    "            else:\n",
    "                index = index_sel\n",
    "            # backward\n",
    "            target = output[i][index]\n",
    "            target.backward(retain_graph=True)\n",
    "\n",
    "            gradient = self.gradient[i].cpu().detach().data.numpy()  # [C,H,W,D]\n",
    "            weight = np.mean(gradient, axis=(1, 2, 3))  # [C]\n",
    "\n",
    "            feature = self.feature[i].cpu().detach().data.numpy()  # [C,H,W,D]\n",
    "            \n",
    "            # np.newaxis 增加維度的方法\n",
    "            cam = feature * weight[:, np.newaxis, np.newaxis, np.newaxis]  # [C,H,W,D] feature map 與 weight相乘\n",
    "            cam = np.sum(cam, axis=0)  # [H,W,D] \n",
    "            cam = np.maximum(cam, 0)  # ReLU\n",
    "            heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "            heatmap = resize(heatmap,inputs.shape[2:5])\n",
    "            heatmap_list.append(heatmap)\n",
    "\n",
    "        return heatmap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_conv_name(net):\n",
    "    \"\"\"\n",
    "    获取网络的最后一个卷积层的名字\n",
    "    :param net:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #layer_name = None\n",
    "    layer_name_list = []\n",
    "    for name, m in net.named_modules():\n",
    "        #print(name)\n",
    "        #print(m)\n",
    "        if isinstance(m, nn.Conv3d):\n",
    "            layer_name_list.append(name)\n",
    "            #layer_name = name\n",
    "    return layer_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "output shape: torch.Size([8, 2])\n",
      "predict:1\n",
      "tensor(-0.0530, device='cuda:0', grad_fn=<SelectBackward>)\n",
      "tensor([[[[[-0.0001, -0.0001, -0.0001, -0.0001],\n",
      "           [-0.0001, -0.0001, -0.0001, -0.0001],\n",
      "           [-0.0001, -0.0001, -0.0001, -0.0001],\n",
      "           [-0.0001, -0.0001, -0.0001, -0.0001]],\n",
      "\n",
      "          [[-0.0002, -0.0001, -0.0001, -0.0001],\n",
      "           [-0.0002, -0.0001, -0.0001, -0.0001],\n",
      "           [-0.0002, -0.0002, -0.0002, -0.0001],\n",
      "           [-0.0001, -0.0001, -0.0001, -0.0001]],\n",
      "\n",
      "          [[-0.0002, -0.0001, -0.0001, -0.0001],\n",
      "           [-0.0002, -0.0001, -0.0001, -0.0001],\n",
      "           [-0.0002, -0.0001, -0.0001, -0.0001],\n",
      "           [-0.0001, -0.0001, -0.0001, -0.0001]],\n",
      "\n",
      "          [[-0.0002, -0.0001, -0.0002, -0.0001],\n",
      "           [-0.0002, -0.0002, -0.0002, -0.0001],\n",
      "           [-0.0002, -0.0002, -0.0002, -0.0001],\n",
      "           [-0.0002, -0.0001, -0.0001, -0.0001]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000]]]]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'resize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-7a5a396c2fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_last_conv_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgrad_cam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradCAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-8cd41f8a856b>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, index_sel)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcam\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mheatmap_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resize' is not defined"
     ]
    }
   ],
   "source": [
    "layer_name = get_last_conv_name(net)[-1]\n",
    "grad_cam = GradCAM(net, layer_name, device)\n",
    "result_list = grad_cam(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "tensor([[[[[ 4.8192e-05, -4.0527e-06, -7.8900e-06, -5.8108e-05],\n",
      "           [ 9.9255e-05,  6.8981e-05,  6.2890e-05, -3.6464e-05],\n",
      "           [ 9.4997e-05,  5.9438e-05,  5.9109e-05, -3.9836e-05],\n",
      "           [-1.9037e-06, -4.0569e-06, -6.6503e-06, -6.8057e-05]],\n",
      "\n",
      "          [[ 2.0735e-05, -9.7266e-05, -9.7874e-05, -1.2328e-04],\n",
      "           [ 8.2801e-05,  9.0794e-06,  8.1685e-06, -7.5284e-05],\n",
      "           [ 8.2110e-05,  5.4205e-06,  7.9309e-06, -7.6713e-05],\n",
      "           [ 9.2403e-06,  1.9504e-06,  1.4520e-07, -7.8511e-05]],\n",
      "\n",
      "          [[ 2.0693e-05, -9.8155e-05, -9.5527e-05, -1.2170e-04],\n",
      "           [ 8.3443e-05,  1.0811e-05,  1.1402e-05, -7.4053e-05],\n",
      "           [ 8.0797e-05,  6.1844e-06,  1.1094e-05, -7.5477e-05],\n",
      "           [ 8.9477e-06,  1.5892e-06,  3.0812e-06, -7.9163e-05]],\n",
      "\n",
      "          [[-1.4726e-06, -1.0927e-04, -1.0783e-04, -1.0267e-04],\n",
      "           [ 8.3580e-05,  1.6677e-05,  1.8811e-05, -2.5017e-05],\n",
      "           [ 8.5469e-05,  1.5626e-05,  1.9419e-05, -2.6637e-05],\n",
      "           [ 5.0051e-05,  3.8137e-05,  3.9777e-05, -4.8305e-06]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.8203e-05, -4.0515e-06, -7.8815e-06, -5.8102e-05],\n",
      "           [ 9.9251e-05,  6.8958e-05,  6.2883e-05, -3.6460e-05],\n",
      "           [ 9.5006e-05,  5.9450e-05,  5.9133e-05, -3.9835e-05],\n",
      "           [-1.8991e-06, -4.0533e-06, -6.6407e-06, -6.8065e-05]],\n",
      "\n",
      "          [[ 2.0734e-05, -9.7268e-05, -9.7881e-05, -1.2327e-04],\n",
      "           [ 8.2793e-05,  9.0646e-06,  8.1673e-06, -7.5288e-05],\n",
      "           [ 8.2126e-05,  5.4414e-06,  7.9327e-06, -7.6710e-05],\n",
      "           [ 9.2251e-06,  1.9439e-06,  1.4149e-07, -7.8517e-05]],\n",
      "\n",
      "          [[ 2.0686e-05, -9.8142e-05, -9.5518e-05, -1.2170e-04],\n",
      "           [ 8.3435e-05,  1.0813e-05,  1.1394e-05, -7.4060e-05],\n",
      "           [ 8.0784e-05,  6.1940e-06,  1.1113e-05, -7.5465e-05],\n",
      "           [ 8.9446e-06,  1.6074e-06,  3.0857e-06, -7.9171e-05]],\n",
      "\n",
      "          [[-1.4677e-06, -1.0927e-04, -1.0783e-04, -1.0267e-04],\n",
      "           [ 8.3565e-05,  1.6661e-05,  1.8822e-05, -2.5027e-05],\n",
      "           [ 8.5478e-05,  1.5649e-05,  1.9426e-05, -2.6635e-05],\n",
      "           [ 5.0037e-05,  3.8131e-05,  3.9778e-05, -4.8221e-06]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.8193e-05, -4.0484e-06, -7.8863e-06, -5.8107e-05],\n",
      "           [ 9.9251e-05,  6.8971e-05,  6.2875e-05, -3.6455e-05],\n",
      "           [ 9.5019e-05,  5.9430e-05,  5.9117e-05, -3.9825e-05],\n",
      "           [-1.9040e-06, -4.0658e-06, -6.6422e-06, -6.8052e-05]],\n",
      "\n",
      "          [[ 2.0727e-05, -9.7259e-05, -9.7890e-05, -1.2327e-04],\n",
      "           [ 8.2807e-05,  9.0883e-06,  8.1498e-06, -7.5282e-05],\n",
      "           [ 8.2120e-05,  5.4451e-06,  7.9225e-06, -7.6709e-05],\n",
      "           [ 9.2459e-06,  1.9331e-06,  1.4263e-07, -7.8521e-05]],\n",
      "\n",
      "          [[ 2.0677e-05, -9.8143e-05, -9.5527e-05, -1.2171e-04],\n",
      "           [ 8.3449e-05,  1.0827e-05,  1.1389e-05, -7.4044e-05],\n",
      "           [ 8.0793e-05,  6.1772e-06,  1.1098e-05, -7.5455e-05],\n",
      "           [ 8.9442e-06,  1.5930e-06,  3.0863e-06, -7.9163e-05]],\n",
      "\n",
      "          [[-1.4638e-06, -1.0927e-04, -1.0784e-04, -1.0267e-04],\n",
      "           [ 8.3576e-05,  1.6685e-05,  1.8814e-05, -2.5021e-05],\n",
      "           [ 8.5470e-05,  1.5645e-05,  1.9402e-05, -2.6633e-05],\n",
      "           [ 5.0045e-05,  3.8131e-05,  3.9775e-05, -4.8226e-06]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.8195e-05, -4.0579e-06, -7.8760e-06, -5.8108e-05],\n",
      "           [ 9.9238e-05,  6.8982e-05,  6.2887e-05, -3.6459e-05],\n",
      "           [ 9.5014e-05,  5.9454e-05,  5.9126e-05, -3.9832e-05],\n",
      "           [-1.9031e-06, -4.0521e-06, -6.6489e-06, -6.8066e-05]],\n",
      "\n",
      "          [[ 2.0723e-05, -9.7264e-05, -9.7877e-05, -1.2327e-04],\n",
      "           [ 8.2800e-05,  9.0713e-06,  8.1717e-06, -7.5282e-05],\n",
      "           [ 8.2086e-05,  5.4517e-06,  7.9332e-06, -7.6708e-05],\n",
      "           [ 9.2402e-06,  1.9515e-06,  1.3341e-07, -7.8521e-05]],\n",
      "\n",
      "          [[ 2.0694e-05, -9.8147e-05, -9.5515e-05, -1.2170e-04],\n",
      "           [ 8.3437e-05,  1.0824e-05,  1.1398e-05, -7.4073e-05],\n",
      "           [ 8.0800e-05,  6.1906e-06,  1.1106e-05, -7.5472e-05],\n",
      "           [ 8.9469e-06,  1.6002e-06,  3.0809e-06, -7.9163e-05]],\n",
      "\n",
      "          [[-1.4659e-06, -1.0928e-04, -1.0783e-04, -1.0267e-04],\n",
      "           [ 8.3579e-05,  1.6662e-05,  1.8823e-05, -2.5028e-05],\n",
      "           [ 8.5475e-05,  1.5653e-05,  1.9417e-05, -2.6634e-05],\n",
      "           [ 5.0044e-05,  3.8132e-05,  3.9760e-05, -4.8233e-06]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.8197e-05, -4.0531e-06, -7.8810e-06, -5.8107e-05],\n",
      "           [ 9.9252e-05,  6.8967e-05,  6.2885e-05, -3.6461e-05],\n",
      "           [ 9.5011e-05,  5.9434e-05,  5.9121e-05, -3.9824e-05],\n",
      "           [-1.9043e-06, -4.0660e-06, -6.6431e-06, -6.8052e-05]],\n",
      "\n",
      "          [[ 2.0734e-05, -9.7267e-05, -9.7886e-05, -1.2326e-04],\n",
      "           [ 8.2801e-05,  9.0755e-06,  8.1588e-06, -7.5269e-05],\n",
      "           [ 8.2109e-05,  5.4448e-06,  7.9501e-06, -7.6710e-05],\n",
      "           [ 9.2370e-06,  1.9459e-06,  1.2675e-07, -7.8523e-05]],\n",
      "\n",
      "          [[ 2.0678e-05, -9.8144e-05, -9.5511e-05, -1.2170e-04],\n",
      "           [ 8.3436e-05,  1.0825e-05,  1.1406e-05, -7.4063e-05],\n",
      "           [ 8.0786e-05,  6.1770e-06,  1.1088e-05, -7.5471e-05],\n",
      "           [ 8.9475e-06,  1.5981e-06,  3.0885e-06, -7.9164e-05]],\n",
      "\n",
      "          [[-1.4594e-06, -1.0926e-04, -1.0782e-04, -1.0266e-04],\n",
      "           [ 8.3573e-05,  1.6661e-05,  1.8813e-05, -2.5025e-05],\n",
      "           [ 8.5473e-05,  1.5643e-05,  1.9429e-05, -2.6636e-05],\n",
      "           [ 5.0043e-05,  3.8137e-05,  3.9773e-05, -4.8244e-06]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.8195e-05, -4.0468e-06, -7.8838e-06, -5.8105e-05],\n",
      "           [ 9.9254e-05,  6.8967e-05,  6.2897e-05, -3.6462e-05],\n",
      "           [ 9.4998e-05,  5.9437e-05,  5.9127e-05, -3.9826e-05],\n",
      "           [-1.9117e-06, -4.0635e-06, -6.6347e-06, -6.8051e-05]],\n",
      "\n",
      "          [[ 2.0734e-05, -9.7259e-05, -9.7874e-05, -1.2327e-04],\n",
      "           [ 8.2799e-05,  9.0817e-06,  8.1525e-06, -7.5284e-05],\n",
      "           [ 8.2112e-05,  5.4309e-06,  7.9310e-06, -7.6707e-05],\n",
      "           [ 9.2398e-06,  1.9455e-06,  1.2045e-07, -7.8512e-05]],\n",
      "\n",
      "          [[ 2.0681e-05, -9.8128e-05, -9.5521e-05, -1.2170e-04],\n",
      "           [ 8.3450e-05,  1.0802e-05,  1.1397e-05, -7.4054e-05],\n",
      "           [ 8.0780e-05,  6.1831e-06,  1.1104e-05, -7.5461e-05],\n",
      "           [ 8.9475e-06,  1.6090e-06,  3.0915e-06, -7.9164e-05]],\n",
      "\n",
      "          [[-1.4616e-06, -1.0928e-04, -1.0783e-04, -1.0267e-04],\n",
      "           [ 8.3566e-05,  1.6653e-05,  1.8804e-05, -2.5024e-05],\n",
      "           [ 8.5482e-05,  1.5634e-05,  1.9421e-05, -2.6638e-05],\n",
      "           [ 5.0045e-05,  3.8132e-05,  3.9771e-05, -4.8267e-06]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.8191e-05, -4.0637e-06, -7.8859e-06, -5.8109e-05],\n",
      "           [ 9.9249e-05,  6.8973e-05,  6.2888e-05, -3.6462e-05],\n",
      "           [ 9.4989e-05,  5.9450e-05,  5.9129e-05, -3.9823e-05],\n",
      "           [-1.9084e-06, -4.0578e-06, -6.6411e-06, -6.8058e-05]],\n",
      "\n",
      "          [[ 2.0732e-05, -9.7276e-05, -9.7889e-05, -1.2327e-04],\n",
      "           [ 8.2800e-05,  9.0846e-06,  8.1753e-06, -7.5269e-05],\n",
      "           [ 8.2102e-05,  5.4312e-06,  7.9376e-06, -7.6701e-05],\n",
      "           [ 9.2302e-06,  1.9427e-06,  1.3305e-07, -7.8528e-05]],\n",
      "\n",
      "          [[ 2.0691e-05, -9.8152e-05, -9.5514e-05, -1.2170e-04],\n",
      "           [ 8.3449e-05,  1.0815e-05,  1.1418e-05, -7.4046e-05],\n",
      "           [ 8.0793e-05,  6.1835e-06,  1.1100e-05, -7.5465e-05],\n",
      "           [ 8.9405e-06,  1.5909e-06,  3.0788e-06, -7.9164e-05]],\n",
      "\n",
      "          [[-1.4670e-06, -1.0927e-04, -1.0783e-04, -1.0266e-04],\n",
      "           [ 8.3581e-05,  1.6664e-05,  1.8811e-05, -2.5020e-05],\n",
      "           [ 8.5468e-05,  1.5627e-05,  1.9404e-05, -2.6638e-05],\n",
      "           [ 5.0048e-05,  3.8137e-05,  3.9776e-05, -4.8222e-06]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.8198e-05, -4.0525e-06, -7.8909e-06, -5.8111e-05],\n",
      "           [ 9.9255e-05,  6.8968e-05,  6.2889e-05, -3.6456e-05],\n",
      "           [ 9.5013e-05,  5.9437e-05,  5.9113e-05, -3.9836e-05],\n",
      "           [-1.9061e-06, -4.0533e-06, -6.6472e-06, -6.8054e-05]],\n",
      "\n",
      "          [[ 2.0734e-05, -9.7265e-05, -9.7892e-05, -1.2327e-04],\n",
      "           [ 8.2796e-05,  9.0903e-06,  8.1589e-06, -7.5283e-05],\n",
      "           [ 8.2107e-05,  5.4581e-06,  7.9204e-06, -7.6717e-05],\n",
      "           [ 9.2405e-06,  1.9442e-06,  1.4835e-07, -7.8504e-05]],\n",
      "\n",
      "          [[ 2.0681e-05, -9.8145e-05, -9.5526e-05, -1.2170e-04],\n",
      "           [ 8.3439e-05,  1.0801e-05,  1.1398e-05, -7.4056e-05],\n",
      "           [ 8.0787e-05,  6.1841e-06,  1.1106e-05, -7.5470e-05],\n",
      "           [ 8.9389e-06,  1.5990e-06,  3.0775e-06, -7.9158e-05]],\n",
      "\n",
      "          [[-1.4589e-06, -1.0928e-04, -1.0783e-04, -1.0267e-04],\n",
      "           [ 8.3574e-05,  1.6676e-05,  1.8824e-05, -2.5022e-05],\n",
      "           [ 8.5473e-05,  1.5640e-05,  1.9405e-05, -2.6633e-05],\n",
      "           [ 5.0043e-05,  3.8139e-05,  3.9783e-05, -4.8138e-06]]]]],\n",
      "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)\n",
      "feature shape:torch.Size([8, 1, 4, 4, 4])\n",
      "<MulBackward0 object at 0x7f8c528a2eb8>\n",
      "tensor([[-0.0835, -0.0530],\n",
      "        [-0.0835, -0.0530],\n",
      "        [-0.0835, -0.0530],\n",
      "        [-0.0835, -0.0530],\n",
      "        [-0.0835, -0.0530],\n",
      "        [-0.0835, -0.0530],\n",
      "        [-0.0835, -0.0530],\n",
      "        [-0.0835, -0.0530]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "<MulBackward0 object at 0x7f8c528a2eb8>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Variable data has to be a tensor, but got tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-eea6ae90f2b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_last_conv_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgrad_cam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradCAM_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-4166bc31c977>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, index_sel)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mheatmap_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m#print(f\"output shape: {output.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Variable data has to be a tensor, but got tuple"
     ]
    }
   ],
   "source": [
    "layer_name = get_last_conv_name(net)[-1]\n",
    "grad_cam = GradCAM_2(net, layer_name, device)\n",
    "result_list = grad_cam(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "tensor(0.3317, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tar = Variable(torch.Tensor(1)).cuda()\n",
    "x = torch.randn((1, 1, 32, 32, 32)).cuda()\n",
    "out = net(x)\n",
    "cre = AngleLoss()\n",
    "loss = cre(out, tar)\n",
    "print(loss)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "val_outputs=AngleLoss_test()(out,tar)\n",
    "#val_outputs = loss_test(out,tar)\n",
    "value = torch.eq(val_outputs.argmax(dim=1), tar)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64, 64, 64], [128, 128, 256], [256, 256, 256, 512]]\n",
      "tensor([[ 1.1392, -0.5168]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "net2 = ConvRes(32,[[64, 64, 64], [128, 128, 256], [256, 256, 256, 512]],normal=True)\n",
    "net2 = net2.cuda()\n",
    "inputs = torch.randn((1, 1, 32, 32, 32)).cuda()\n",
    "labels = torch.randn((1)).cuda()\n",
    "output = net2(inputs)\n",
    "print(net2.config)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngleLoss_test(nn.Module):\n",
    "    def __init__(self, gamma=0):\n",
    "        super(AngleLoss_test, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.it = 1\n",
    "        self.LambdaMin = 5.0\n",
    "        self.LambdaMax = 1500.0\n",
    "        self.lamb = 1500.0\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        cos_theta, phi_theta = input\n",
    "        target = target.view(-1, 1)  # size=(B,1)\n",
    "        index = cos_theta.data * 0.0  # size=(B, Classnum)\n",
    "        # index = index.scatter(1, target.data.view(-1, 1).long(), 1)\n",
    "        #index = index.byte()\n",
    "        index = index.bool()  \n",
    "        index = Variable(index)\n",
    "        # index = Variable(torch.randn(1,2)).byte()\n",
    "\n",
    "        self.lamb = max(self.LambdaMin, self.LambdaMax / (1 + 0.1 * self.it))\n",
    "        output = cos_theta * 1.0  # size=(B,Classnum)\n",
    "        output1 = output.clone()\n",
    "        # output1[index1] = output[index] - cos_theta[index] * (1.0 + 0) / (1 + self.lamb)\n",
    "        # output1[index1] = output[index] + phi_theta[index] * (1.0 + 0) / (1 + self.lamb)\n",
    "        output[index] = output1[index]- cos_theta[index] * (1.0 + 0) / (1 + self.lamb)+ phi_theta[index] * (1.0 + 0) / (1 + self.lamb)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'argmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5896ba872902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmetric_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmetric_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'argmax'"
     ]
    }
   ],
   "source": [
    "value = torch.eq(out.argmax(dim=1), val_labels)\n",
    "metric_count += len(value)\n",
    "num_correct += value.sum().item()\n",
    "metric = num_correct / metric_count\n",
    "config.metric_values.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = ConvRes(64,[[64, 64, 64], [128, 128, 256], [256, 256, 256, 512]])\n",
    "net2 = net2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([512, 2])\n",
      "Parameter containing:\n",
      "tensor([[-0.0089,  0.0317],\n",
      "        [ 0.0261,  0.0550],\n",
      "        [ 0.0073, -0.0149],\n",
      "        ...,\n",
      "        [ 0.0007, -0.0344],\n",
      "        [-0.0294, -0.0512],\n",
      "        [-0.0696, -0.0571]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([512, 2])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn((1, 1, 64, 64, 64)).cuda()\n",
    "output = net2(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([512, 2])\n",
      "Parameter containing:\n",
      "tensor([[-0.0730,  0.0627],\n",
      "        [-0.0516, -0.0192],\n",
      "        [ 0.0367, -0.0305],\n",
      "        ...,\n",
      "        [ 0.0088,  0.0687],\n",
      "        [ 0.0025, -0.0658],\n",
      "        [ 0.0702, -0.0125]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([512, 2])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1        [-1, 4, 32, 32, 32]             112\n",
      "       BatchNorm3d-2        [-1, 4, 32, 32, 32]               8\n",
      "              ReLU-3        [-1, 4, 32, 32, 32]               0\n",
      "            Conv3d-4        [-1, 4, 32, 32, 32]             436\n",
      "       BatchNorm3d-5        [-1, 4, 32, 32, 32]               8\n",
      "              ReLU-6        [-1, 4, 32, 32, 32]               0\n",
      "         AvgPool3d-7           [-1, 4, 1, 1, 1]               0\n",
      "         MaxPool3d-8           [-1, 4, 1, 1, 1]               0\n",
      "            Linear-9                    [-1, 1]               4\n",
      "           Linear-10                    [-1, 4]               4\n",
      "           Linear-11                    [-1, 1]               4\n",
      "           Linear-12                    [-1, 4]               4\n",
      "          Softmax-13                    [-1, 4]               0\n",
      "           Conv3d-14        [-1, 1, 32, 32, 32]              54\n",
      "          Sigmoid-15                [-1, 32768]               0\n",
      "     ResCBAMLayer-16        [-1, 4, 32, 32, 32]               0\n",
      "           Conv3d-17        [-1, 4, 16, 16, 16]             432\n",
      "      BatchNorm3d-18        [-1, 4, 16, 16, 16]               8\n",
      "             ReLU-19        [-1, 4, 16, 16, 16]               0\n",
      "           Conv3d-20       [-1, 64, 16, 16, 16]             320\n",
      "      BatchNorm3d-21       [-1, 64, 16, 16, 16]             128\n",
      "             ReLU-22       [-1, 64, 16, 16, 16]               0\n",
      "           Conv3d-23       [-1, 64, 16, 16, 16]           6,976\n",
      "      BatchNorm3d-24       [-1, 64, 16, 16, 16]             128\n",
      "             ReLU-25       [-1, 64, 16, 16, 16]               0\n",
      "           Conv3d-26       [-1, 64, 16, 16, 16]         110,656\n",
      "      BatchNorm3d-27       [-1, 64, 16, 16, 16]             128\n",
      "             ReLU-28       [-1, 64, 16, 16, 16]               0\n",
      "    ResidualBlock-29       [-1, 64, 16, 16, 16]               0\n",
      "           Conv3d-30       [-1, 64, 16, 16, 16]           4,160\n",
      "      BatchNorm3d-31       [-1, 64, 16, 16, 16]             128\n",
      "             ReLU-32       [-1, 64, 16, 16, 16]               0\n",
      "           Conv3d-33       [-1, 64, 16, 16, 16]         110,656\n",
      "      BatchNorm3d-34       [-1, 64, 16, 16, 16]             128\n",
      "             ReLU-35       [-1, 64, 16, 16, 16]               0\n",
      "           Conv3d-36       [-1, 64, 16, 16, 16]         110,656\n",
      "      BatchNorm3d-37       [-1, 64, 16, 16, 16]             128\n",
      "             ReLU-38       [-1, 64, 16, 16, 16]               0\n",
      "    ResidualBlock-39       [-1, 64, 16, 16, 16]               0\n",
      "           Conv3d-40       [-1, 64, 16, 16, 16]           4,160\n",
      "      BatchNorm3d-41       [-1, 64, 16, 16, 16]             128\n",
      "             ReLU-42       [-1, 64, 16, 16, 16]               0\n",
      "           Conv3d-43       [-1, 64, 16, 16, 16]         110,656\n",
      "      BatchNorm3d-44       [-1, 64, 16, 16, 16]             128\n",
      "             ReLU-45       [-1, 64, 16, 16, 16]               0\n",
      "           Conv3d-46       [-1, 64, 16, 16, 16]         110,656\n",
      "      BatchNorm3d-47       [-1, 64, 16, 16, 16]             128\n",
      "             ReLU-48       [-1, 64, 16, 16, 16]               0\n",
      "    ResidualBlock-49       [-1, 64, 16, 16, 16]               0\n",
      "        AvgPool3d-50          [-1, 64, 1, 1, 1]               0\n",
      "        MaxPool3d-51          [-1, 64, 1, 1, 1]               0\n",
      "           Linear-52                   [-1, 16]           1,024\n",
      "           Linear-53                   [-1, 64]           1,024\n",
      "           Linear-54                   [-1, 16]           1,024\n",
      "           Linear-55                   [-1, 64]           1,024\n",
      "          Softmax-56                   [-1, 64]               0\n",
      "           Conv3d-57        [-1, 1, 16, 16, 16]              54\n",
      "          Sigmoid-58                 [-1, 4096]               0\n",
      "     ResCBAMLayer-59       [-1, 64, 16, 16, 16]               0\n",
      "           Conv3d-60          [-1, 64, 8, 8, 8]         110,592\n",
      "      BatchNorm3d-61          [-1, 64, 8, 8, 8]             128\n",
      "             ReLU-62          [-1, 64, 8, 8, 8]               0\n",
      "           Conv3d-63         [-1, 128, 8, 8, 8]           8,320\n",
      "      BatchNorm3d-64         [-1, 128, 8, 8, 8]             256\n",
      "             ReLU-65         [-1, 128, 8, 8, 8]               0\n",
      "           Conv3d-66         [-1, 128, 8, 8, 8]         221,312\n",
      "      BatchNorm3d-67         [-1, 128, 8, 8, 8]             256\n",
      "             ReLU-68         [-1, 128, 8, 8, 8]               0\n",
      "           Conv3d-69         [-1, 128, 8, 8, 8]         442,496\n",
      "      BatchNorm3d-70         [-1, 128, 8, 8, 8]             256\n",
      "             ReLU-71         [-1, 128, 8, 8, 8]               0\n",
      "    ResidualBlock-72         [-1, 128, 8, 8, 8]               0\n",
      "           Conv3d-73         [-1, 128, 8, 8, 8]          16,512\n",
      "      BatchNorm3d-74         [-1, 128, 8, 8, 8]             256\n",
      "             ReLU-75         [-1, 128, 8, 8, 8]               0\n",
      "           Conv3d-76         [-1, 128, 8, 8, 8]         442,496\n",
      "      BatchNorm3d-77         [-1, 128, 8, 8, 8]             256\n",
      "             ReLU-78         [-1, 128, 8, 8, 8]               0\n",
      "           Conv3d-79         [-1, 128, 8, 8, 8]         442,496\n",
      "      BatchNorm3d-80         [-1, 128, 8, 8, 8]             256\n",
      "             ReLU-81         [-1, 128, 8, 8, 8]               0\n",
      "    ResidualBlock-82         [-1, 128, 8, 8, 8]               0\n",
      "           Conv3d-83         [-1, 256, 8, 8, 8]          33,024\n",
      "      BatchNorm3d-84         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-85         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-86         [-1, 256, 8, 8, 8]         884,992\n",
      "      BatchNorm3d-87         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-88         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-89         [-1, 256, 8, 8, 8]       1,769,728\n",
      "      BatchNorm3d-90         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-91         [-1, 256, 8, 8, 8]               0\n",
      "    ResidualBlock-92         [-1, 256, 8, 8, 8]               0\n",
      "        AvgPool3d-93         [-1, 256, 1, 1, 1]               0\n",
      "        MaxPool3d-94         [-1, 256, 1, 1, 1]               0\n",
      "           Linear-95                   [-1, 64]          16,384\n",
      "           Linear-96                  [-1, 256]          16,384\n",
      "           Linear-97                   [-1, 64]          16,384\n",
      "           Linear-98                  [-1, 256]          16,384\n",
      "          Softmax-99                  [-1, 256]               0\n",
      "          Conv3d-100           [-1, 1, 8, 8, 8]              54\n",
      "         Sigmoid-101                  [-1, 512]               0\n",
      "    ResCBAMLayer-102         [-1, 256, 8, 8, 8]               0\n",
      "          Conv3d-103         [-1, 256, 4, 4, 4]       1,769,472\n",
      "     BatchNorm3d-104         [-1, 256, 4, 4, 4]             512\n",
      "            ReLU-105         [-1, 256, 4, 4, 4]               0\n",
      "          Conv3d-106         [-1, 256, 4, 4, 4]          65,792\n",
      "     BatchNorm3d-107         [-1, 256, 4, 4, 4]             512\n",
      "            ReLU-108         [-1, 256, 4, 4, 4]               0\n",
      "          Conv3d-109         [-1, 256, 4, 4, 4]       1,769,728\n",
      "     BatchNorm3d-110         [-1, 256, 4, 4, 4]             512\n",
      "            ReLU-111         [-1, 256, 4, 4, 4]               0\n",
      "          Conv3d-112         [-1, 256, 4, 4, 4]       1,769,728\n",
      "     BatchNorm3d-113         [-1, 256, 4, 4, 4]             512\n",
      "            ReLU-114         [-1, 256, 4, 4, 4]               0\n",
      "   ResidualBlock-115         [-1, 256, 4, 4, 4]               0\n",
      "          Conv3d-116         [-1, 256, 4, 4, 4]          65,792\n",
      "     BatchNorm3d-117         [-1, 256, 4, 4, 4]             512\n",
      "            ReLU-118         [-1, 256, 4, 4, 4]               0\n",
      "          Conv3d-119         [-1, 256, 4, 4, 4]       1,769,728\n",
      "     BatchNorm3d-120         [-1, 256, 4, 4, 4]             512\n",
      "            ReLU-121         [-1, 256, 4, 4, 4]               0\n",
      "          Conv3d-122         [-1, 256, 4, 4, 4]       1,769,728\n",
      "     BatchNorm3d-123         [-1, 256, 4, 4, 4]             512\n",
      "            ReLU-124         [-1, 256, 4, 4, 4]               0\n",
      "   ResidualBlock-125         [-1, 256, 4, 4, 4]               0\n",
      "          Conv3d-126         [-1, 256, 4, 4, 4]          65,792\n",
      "     BatchNorm3d-127         [-1, 256, 4, 4, 4]             512\n",
      "            ReLU-128         [-1, 256, 4, 4, 4]               0\n",
      "          Conv3d-129         [-1, 256, 4, 4, 4]       1,769,728\n",
      "     BatchNorm3d-130         [-1, 256, 4, 4, 4]             512\n",
      "            ReLU-131         [-1, 256, 4, 4, 4]               0\n",
      "          Conv3d-132         [-1, 256, 4, 4, 4]       1,769,728\n",
      "     BatchNorm3d-133         [-1, 256, 4, 4, 4]             512\n",
      "            ReLU-134         [-1, 256, 4, 4, 4]               0\n",
      "   ResidualBlock-135         [-1, 256, 4, 4, 4]               0\n",
      "          Conv3d-136         [-1, 512, 4, 4, 4]         131,584\n",
      "     BatchNorm3d-137         [-1, 512, 4, 4, 4]           1,024\n",
      "            ReLU-138         [-1, 512, 4, 4, 4]               0\n",
      "          Conv3d-139         [-1, 512, 4, 4, 4]       3,539,456\n",
      "     BatchNorm3d-140         [-1, 512, 4, 4, 4]           1,024\n",
      "            ReLU-141         [-1, 512, 4, 4, 4]               0\n",
      "          Conv3d-142         [-1, 512, 4, 4, 4]       7,078,400\n",
      "     BatchNorm3d-143         [-1, 512, 4, 4, 4]           1,024\n",
      "            ReLU-144         [-1, 512, 4, 4, 4]               0\n",
      "   ResidualBlock-145         [-1, 512, 4, 4, 4]               0\n",
      "       AvgPool3d-146         [-1, 512, 1, 1, 1]               0\n",
      "       MaxPool3d-147         [-1, 512, 1, 1, 1]               0\n",
      "          Linear-148                  [-1, 128]          65,536\n",
      "          Linear-149                  [-1, 512]          65,536\n",
      "          Linear-150                  [-1, 128]          65,536\n",
      "          Linear-151                  [-1, 512]          65,536\n",
      "         Softmax-152                  [-1, 512]               0\n",
      "          Conv3d-153           [-1, 1, 4, 4, 4]              54\n",
      "         Sigmoid-154                   [-1, 64]               0\n",
      "    ResCBAMLayer-155         [-1, 512, 4, 4, 4]               0\n",
      "       AvgPool3d-156         [-1, 512, 1, 1, 1]               0\n",
      "     AngleLinear-157         [[-1, 2], [-1, 2]]           1,024\n",
      "================================================================\n",
      "Total params: 28,622,100\n",
      "Trainable params: 28,622,100\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 98.61\n",
      "Params size (MB): 109.18\n",
      "Estimated Total Size (MB): 207.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,(1,32,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([512, 2])\n",
      "Parameter containing:\n",
      "tensor([[-0.0089,  0.0317],\n",
      "        [ 0.0261,  0.0550],\n",
      "        [ 0.0073, -0.0149],\n",
      "        ...,\n",
      "        [ 0.0007, -0.0344],\n",
      "        [-0.0294, -0.0512],\n",
      "        [-0.0696, -0.0571]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([512, 2])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1        [-1, 4, 64, 64, 64]             112\n",
      "       BatchNorm3d-2        [-1, 4, 64, 64, 64]               8\n",
      "              ReLU-3        [-1, 4, 64, 64, 64]               0\n",
      "            Conv3d-4        [-1, 4, 64, 64, 64]             436\n",
      "       BatchNorm3d-5        [-1, 4, 64, 64, 64]               8\n",
      "              ReLU-6        [-1, 4, 64, 64, 64]               0\n",
      "         AvgPool3d-7           [-1, 4, 1, 1, 1]               0\n",
      "         MaxPool3d-8           [-1, 4, 1, 1, 1]               0\n",
      "            Linear-9                    [-1, 1]               4\n",
      "           Linear-10                    [-1, 4]               4\n",
      "           Linear-11                    [-1, 1]               4\n",
      "           Linear-12                    [-1, 4]               4\n",
      "          Softmax-13                    [-1, 4]               0\n",
      "           Conv3d-14        [-1, 1, 64, 64, 64]              54\n",
      "          Sigmoid-15               [-1, 262144]               0\n",
      "     ResCBAMLayer-16        [-1, 4, 64, 64, 64]               0\n",
      "           Conv3d-17        [-1, 4, 32, 32, 32]             432\n",
      "      BatchNorm3d-18        [-1, 4, 32, 32, 32]               8\n",
      "             ReLU-19        [-1, 4, 32, 32, 32]               0\n",
      "           Conv3d-20       [-1, 64, 32, 32, 32]             320\n",
      "      BatchNorm3d-21       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-22       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-23       [-1, 64, 32, 32, 32]           6,976\n",
      "      BatchNorm3d-24       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-25       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-26       [-1, 64, 32, 32, 32]         110,656\n",
      "      BatchNorm3d-27       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-28       [-1, 64, 32, 32, 32]               0\n",
      "    ResidualBlock-29       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-30       [-1, 64, 32, 32, 32]           4,160\n",
      "      BatchNorm3d-31       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-32       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-33       [-1, 64, 32, 32, 32]         110,656\n",
      "      BatchNorm3d-34       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-35       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-36       [-1, 64, 32, 32, 32]         110,656\n",
      "      BatchNorm3d-37       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-38       [-1, 64, 32, 32, 32]               0\n",
      "    ResidualBlock-39       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-40       [-1, 64, 32, 32, 32]           4,160\n",
      "      BatchNorm3d-41       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-42       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-43       [-1, 64, 32, 32, 32]         110,656\n",
      "      BatchNorm3d-44       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-45       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-46       [-1, 64, 32, 32, 32]         110,656\n",
      "      BatchNorm3d-47       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-48       [-1, 64, 32, 32, 32]               0\n",
      "    ResidualBlock-49       [-1, 64, 32, 32, 32]               0\n",
      "        AvgPool3d-50          [-1, 64, 1, 1, 1]               0\n",
      "        MaxPool3d-51          [-1, 64, 1, 1, 1]               0\n",
      "           Linear-52                   [-1, 16]           1,024\n",
      "           Linear-53                   [-1, 64]           1,024\n",
      "           Linear-54                   [-1, 16]           1,024\n",
      "           Linear-55                   [-1, 64]           1,024\n",
      "          Softmax-56                   [-1, 64]               0\n",
      "           Conv3d-57        [-1, 1, 32, 32, 32]              54\n",
      "          Sigmoid-58                [-1, 32768]               0\n",
      "     ResCBAMLayer-59       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-60       [-1, 64, 16, 16, 16]         110,592\n",
      "      BatchNorm3d-61       [-1, 64, 16, 16, 16]             128\n",
      "             ReLU-62       [-1, 64, 16, 16, 16]               0\n",
      "           Conv3d-63      [-1, 128, 16, 16, 16]           8,320\n",
      "      BatchNorm3d-64      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-65      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-66      [-1, 128, 16, 16, 16]         221,312\n",
      "      BatchNorm3d-67      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-68      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-69      [-1, 128, 16, 16, 16]         442,496\n",
      "      BatchNorm3d-70      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-71      [-1, 128, 16, 16, 16]               0\n",
      "    ResidualBlock-72      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-73      [-1, 128, 16, 16, 16]          16,512\n",
      "      BatchNorm3d-74      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-75      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-76      [-1, 128, 16, 16, 16]         442,496\n",
      "      BatchNorm3d-77      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-78      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-79      [-1, 128, 16, 16, 16]         442,496\n",
      "      BatchNorm3d-80      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-81      [-1, 128, 16, 16, 16]               0\n",
      "    ResidualBlock-82      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-83      [-1, 256, 16, 16, 16]          33,024\n",
      "      BatchNorm3d-84      [-1, 256, 16, 16, 16]             512\n",
      "             ReLU-85      [-1, 256, 16, 16, 16]               0\n",
      "           Conv3d-86      [-1, 256, 16, 16, 16]         884,992\n",
      "      BatchNorm3d-87      [-1, 256, 16, 16, 16]             512\n",
      "             ReLU-88      [-1, 256, 16, 16, 16]               0\n",
      "           Conv3d-89      [-1, 256, 16, 16, 16]       1,769,728\n",
      "      BatchNorm3d-90      [-1, 256, 16, 16, 16]             512\n",
      "             ReLU-91      [-1, 256, 16, 16, 16]               0\n",
      "    ResidualBlock-92      [-1, 256, 16, 16, 16]               0\n",
      "        AvgPool3d-93         [-1, 256, 1, 1, 1]               0\n",
      "        MaxPool3d-94         [-1, 256, 1, 1, 1]               0\n",
      "           Linear-95                   [-1, 64]          16,384\n",
      "           Linear-96                  [-1, 256]          16,384\n",
      "           Linear-97                   [-1, 64]          16,384\n",
      "           Linear-98                  [-1, 256]          16,384\n",
      "          Softmax-99                  [-1, 256]               0\n",
      "          Conv3d-100        [-1, 1, 16, 16, 16]              54\n",
      "         Sigmoid-101                 [-1, 4096]               0\n",
      "    ResCBAMLayer-102      [-1, 256, 16, 16, 16]               0\n",
      "          Conv3d-103         [-1, 256, 8, 8, 8]       1,769,472\n",
      "     BatchNorm3d-104         [-1, 256, 8, 8, 8]             512\n",
      "            ReLU-105         [-1, 256, 8, 8, 8]               0\n",
      "          Conv3d-106         [-1, 256, 8, 8, 8]          65,792\n",
      "     BatchNorm3d-107         [-1, 256, 8, 8, 8]             512\n",
      "            ReLU-108         [-1, 256, 8, 8, 8]               0\n",
      "          Conv3d-109         [-1, 256, 8, 8, 8]       1,769,728\n",
      "     BatchNorm3d-110         [-1, 256, 8, 8, 8]             512\n",
      "            ReLU-111         [-1, 256, 8, 8, 8]               0\n",
      "          Conv3d-112         [-1, 256, 8, 8, 8]       1,769,728\n",
      "     BatchNorm3d-113         [-1, 256, 8, 8, 8]             512\n",
      "            ReLU-114         [-1, 256, 8, 8, 8]               0\n",
      "   ResidualBlock-115         [-1, 256, 8, 8, 8]               0\n",
      "          Conv3d-116         [-1, 256, 8, 8, 8]          65,792\n",
      "     BatchNorm3d-117         [-1, 256, 8, 8, 8]             512\n",
      "            ReLU-118         [-1, 256, 8, 8, 8]               0\n",
      "          Conv3d-119         [-1, 256, 8, 8, 8]       1,769,728\n",
      "     BatchNorm3d-120         [-1, 256, 8, 8, 8]             512\n",
      "            ReLU-121         [-1, 256, 8, 8, 8]               0\n",
      "          Conv3d-122         [-1, 256, 8, 8, 8]       1,769,728\n",
      "     BatchNorm3d-123         [-1, 256, 8, 8, 8]             512\n",
      "            ReLU-124         [-1, 256, 8, 8, 8]               0\n",
      "   ResidualBlock-125         [-1, 256, 8, 8, 8]               0\n",
      "          Conv3d-126         [-1, 256, 8, 8, 8]          65,792\n",
      "     BatchNorm3d-127         [-1, 256, 8, 8, 8]             512\n",
      "            ReLU-128         [-1, 256, 8, 8, 8]               0\n",
      "          Conv3d-129         [-1, 256, 8, 8, 8]       1,769,728\n",
      "     BatchNorm3d-130         [-1, 256, 8, 8, 8]             512\n",
      "            ReLU-131         [-1, 256, 8, 8, 8]               0\n",
      "          Conv3d-132         [-1, 256, 8, 8, 8]       1,769,728\n",
      "     BatchNorm3d-133         [-1, 256, 8, 8, 8]             512\n",
      "            ReLU-134         [-1, 256, 8, 8, 8]               0\n",
      "   ResidualBlock-135         [-1, 256, 8, 8, 8]               0\n",
      "          Conv3d-136         [-1, 512, 8, 8, 8]         131,584\n",
      "     BatchNorm3d-137         [-1, 512, 8, 8, 8]           1,024\n",
      "            ReLU-138         [-1, 512, 8, 8, 8]               0\n",
      "          Conv3d-139         [-1, 512, 8, 8, 8]       3,539,456\n",
      "     BatchNorm3d-140         [-1, 512, 8, 8, 8]           1,024\n",
      "            ReLU-141         [-1, 512, 8, 8, 8]               0\n",
      "          Conv3d-142         [-1, 512, 8, 8, 8]       7,078,400\n",
      "     BatchNorm3d-143         [-1, 512, 8, 8, 8]           1,024\n",
      "            ReLU-144         [-1, 512, 8, 8, 8]               0\n",
      "   ResidualBlock-145         [-1, 512, 8, 8, 8]               0\n",
      "       AvgPool3d-146         [-1, 512, 1, 1, 1]               0\n",
      "       MaxPool3d-147         [-1, 512, 1, 1, 1]               0\n",
      "          Linear-148                  [-1, 128]          65,536\n",
      "          Linear-149                  [-1, 512]          65,536\n",
      "          Linear-150                  [-1, 128]          65,536\n",
      "          Linear-151                  [-1, 512]          65,536\n",
      "         Softmax-152                  [-1, 512]               0\n",
      "          Conv3d-153           [-1, 1, 8, 8, 8]              54\n",
      "         Sigmoid-154                  [-1, 512]               0\n",
      "    ResCBAMLayer-155         [-1, 512, 8, 8, 8]               0\n",
      "       AvgPool3d-156         [-1, 512, 1, 1, 1]               0\n",
      "     AngleLinear-157         [[-1, 2], [-1, 2]]           1,024\n",
      "================================================================\n",
      "Total params: 28,622,100\n",
      "Trainable params: 28,622,100\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.00\n",
      "Forward/backward pass size (MB): 788.61\n",
      "Params size (MB): 109.18\n",
      "Estimated Total Size (MB): 898.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net2,(1,64,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet.densenet121(spatial_dims=3, in_channels=1, out_channels=2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 64, 64, 64, 64]          21,952\n",
      "       BatchNorm3d-2       [-1, 64, 64, 64, 64]             128\n",
      "              ReLU-3       [-1, 64, 64, 64, 64]               0\n",
      "         MaxPool3d-4       [-1, 64, 32, 32, 32]               0\n",
      "       BatchNorm3d-5       [-1, 64, 32, 32, 32]             128\n",
      "              ReLU-6       [-1, 64, 32, 32, 32]               0\n",
      "            Conv3d-7      [-1, 128, 32, 32, 32]           8,192\n",
      "       BatchNorm3d-8      [-1, 128, 32, 32, 32]             256\n",
      "              ReLU-9      [-1, 128, 32, 32, 32]               0\n",
      "           Conv3d-10       [-1, 32, 32, 32, 32]         110,592\n",
      "      _DenseLayer-11       [-1, 96, 32, 32, 32]               0\n",
      "      BatchNorm3d-12       [-1, 96, 32, 32, 32]             192\n",
      "             ReLU-13       [-1, 96, 32, 32, 32]               0\n",
      "           Conv3d-14      [-1, 128, 32, 32, 32]          12,288\n",
      "      BatchNorm3d-15      [-1, 128, 32, 32, 32]             256\n",
      "             ReLU-16      [-1, 128, 32, 32, 32]               0\n",
      "           Conv3d-17       [-1, 32, 32, 32, 32]         110,592\n",
      "      _DenseLayer-18      [-1, 128, 32, 32, 32]               0\n",
      "      BatchNorm3d-19      [-1, 128, 32, 32, 32]             256\n",
      "             ReLU-20      [-1, 128, 32, 32, 32]               0\n",
      "           Conv3d-21      [-1, 128, 32, 32, 32]          16,384\n",
      "      BatchNorm3d-22      [-1, 128, 32, 32, 32]             256\n",
      "             ReLU-23      [-1, 128, 32, 32, 32]               0\n",
      "           Conv3d-24       [-1, 32, 32, 32, 32]         110,592\n",
      "      _DenseLayer-25      [-1, 160, 32, 32, 32]               0\n",
      "      BatchNorm3d-26      [-1, 160, 32, 32, 32]             320\n",
      "             ReLU-27      [-1, 160, 32, 32, 32]               0\n",
      "           Conv3d-28      [-1, 128, 32, 32, 32]          20,480\n",
      "      BatchNorm3d-29      [-1, 128, 32, 32, 32]             256\n",
      "             ReLU-30      [-1, 128, 32, 32, 32]               0\n",
      "           Conv3d-31       [-1, 32, 32, 32, 32]         110,592\n",
      "      _DenseLayer-32      [-1, 192, 32, 32, 32]               0\n",
      "      BatchNorm3d-33      [-1, 192, 32, 32, 32]             384\n",
      "             ReLU-34      [-1, 192, 32, 32, 32]               0\n",
      "           Conv3d-35      [-1, 128, 32, 32, 32]          24,576\n",
      "      BatchNorm3d-36      [-1, 128, 32, 32, 32]             256\n",
      "             ReLU-37      [-1, 128, 32, 32, 32]               0\n",
      "           Conv3d-38       [-1, 32, 32, 32, 32]         110,592\n",
      "      _DenseLayer-39      [-1, 224, 32, 32, 32]               0\n",
      "      BatchNorm3d-40      [-1, 224, 32, 32, 32]             448\n",
      "             ReLU-41      [-1, 224, 32, 32, 32]               0\n",
      "           Conv3d-42      [-1, 128, 32, 32, 32]          28,672\n",
      "      BatchNorm3d-43      [-1, 128, 32, 32, 32]             256\n",
      "             ReLU-44      [-1, 128, 32, 32, 32]               0\n",
      "           Conv3d-45       [-1, 32, 32, 32, 32]         110,592\n",
      "      _DenseLayer-46      [-1, 256, 32, 32, 32]               0\n",
      "      BatchNorm3d-47      [-1, 256, 32, 32, 32]             512\n",
      "             ReLU-48      [-1, 256, 32, 32, 32]               0\n",
      "           Conv3d-49      [-1, 128, 32, 32, 32]          32,768\n",
      "        AvgPool3d-50      [-1, 128, 16, 16, 16]               0\n",
      "      BatchNorm3d-51      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-52      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-53      [-1, 128, 16, 16, 16]          16,384\n",
      "      BatchNorm3d-54      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-55      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-56       [-1, 32, 16, 16, 16]         110,592\n",
      "      _DenseLayer-57      [-1, 160, 16, 16, 16]               0\n",
      "      BatchNorm3d-58      [-1, 160, 16, 16, 16]             320\n",
      "             ReLU-59      [-1, 160, 16, 16, 16]               0\n",
      "           Conv3d-60      [-1, 128, 16, 16, 16]          20,480\n",
      "      BatchNorm3d-61      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-62      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-63       [-1, 32, 16, 16, 16]         110,592\n",
      "      _DenseLayer-64      [-1, 192, 16, 16, 16]               0\n",
      "      BatchNorm3d-65      [-1, 192, 16, 16, 16]             384\n",
      "             ReLU-66      [-1, 192, 16, 16, 16]               0\n",
      "           Conv3d-67      [-1, 128, 16, 16, 16]          24,576\n",
      "      BatchNorm3d-68      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-69      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-70       [-1, 32, 16, 16, 16]         110,592\n",
      "      _DenseLayer-71      [-1, 224, 16, 16, 16]               0\n",
      "      BatchNorm3d-72      [-1, 224, 16, 16, 16]             448\n",
      "             ReLU-73      [-1, 224, 16, 16, 16]               0\n",
      "           Conv3d-74      [-1, 128, 16, 16, 16]          28,672\n",
      "      BatchNorm3d-75      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-76      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-77       [-1, 32, 16, 16, 16]         110,592\n",
      "      _DenseLayer-78      [-1, 256, 16, 16, 16]               0\n",
      "      BatchNorm3d-79      [-1, 256, 16, 16, 16]             512\n",
      "             ReLU-80      [-1, 256, 16, 16, 16]               0\n",
      "           Conv3d-81      [-1, 128, 16, 16, 16]          32,768\n",
      "      BatchNorm3d-82      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-83      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-84       [-1, 32, 16, 16, 16]         110,592\n",
      "      _DenseLayer-85      [-1, 288, 16, 16, 16]               0\n",
      "      BatchNorm3d-86      [-1, 288, 16, 16, 16]             576\n",
      "             ReLU-87      [-1, 288, 16, 16, 16]               0\n",
      "           Conv3d-88      [-1, 128, 16, 16, 16]          36,864\n",
      "      BatchNorm3d-89      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-90      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-91       [-1, 32, 16, 16, 16]         110,592\n",
      "      _DenseLayer-92      [-1, 320, 16, 16, 16]               0\n",
      "      BatchNorm3d-93      [-1, 320, 16, 16, 16]             640\n",
      "             ReLU-94      [-1, 320, 16, 16, 16]               0\n",
      "           Conv3d-95      [-1, 128, 16, 16, 16]          40,960\n",
      "      BatchNorm3d-96      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-97      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-98       [-1, 32, 16, 16, 16]         110,592\n",
      "      _DenseLayer-99      [-1, 352, 16, 16, 16]               0\n",
      "     BatchNorm3d-100      [-1, 352, 16, 16, 16]             704\n",
      "            ReLU-101      [-1, 352, 16, 16, 16]               0\n",
      "          Conv3d-102      [-1, 128, 16, 16, 16]          45,056\n",
      "     BatchNorm3d-103      [-1, 128, 16, 16, 16]             256\n",
      "            ReLU-104      [-1, 128, 16, 16, 16]               0\n",
      "          Conv3d-105       [-1, 32, 16, 16, 16]         110,592\n",
      "     _DenseLayer-106      [-1, 384, 16, 16, 16]               0\n",
      "     BatchNorm3d-107      [-1, 384, 16, 16, 16]             768\n",
      "            ReLU-108      [-1, 384, 16, 16, 16]               0\n",
      "          Conv3d-109      [-1, 128, 16, 16, 16]          49,152\n",
      "     BatchNorm3d-110      [-1, 128, 16, 16, 16]             256\n",
      "            ReLU-111      [-1, 128, 16, 16, 16]               0\n",
      "          Conv3d-112       [-1, 32, 16, 16, 16]         110,592\n",
      "     _DenseLayer-113      [-1, 416, 16, 16, 16]               0\n",
      "     BatchNorm3d-114      [-1, 416, 16, 16, 16]             832\n",
      "            ReLU-115      [-1, 416, 16, 16, 16]               0\n",
      "          Conv3d-116      [-1, 128, 16, 16, 16]          53,248\n",
      "     BatchNorm3d-117      [-1, 128, 16, 16, 16]             256\n",
      "            ReLU-118      [-1, 128, 16, 16, 16]               0\n",
      "          Conv3d-119       [-1, 32, 16, 16, 16]         110,592\n",
      "     _DenseLayer-120      [-1, 448, 16, 16, 16]               0\n",
      "     BatchNorm3d-121      [-1, 448, 16, 16, 16]             896\n",
      "            ReLU-122      [-1, 448, 16, 16, 16]               0\n",
      "          Conv3d-123      [-1, 128, 16, 16, 16]          57,344\n",
      "     BatchNorm3d-124      [-1, 128, 16, 16, 16]             256\n",
      "            ReLU-125      [-1, 128, 16, 16, 16]               0\n",
      "          Conv3d-126       [-1, 32, 16, 16, 16]         110,592\n",
      "     _DenseLayer-127      [-1, 480, 16, 16, 16]               0\n",
      "     BatchNorm3d-128      [-1, 480, 16, 16, 16]             960\n",
      "            ReLU-129      [-1, 480, 16, 16, 16]               0\n",
      "          Conv3d-130      [-1, 128, 16, 16, 16]          61,440\n",
      "     BatchNorm3d-131      [-1, 128, 16, 16, 16]             256\n",
      "            ReLU-132      [-1, 128, 16, 16, 16]               0\n",
      "          Conv3d-133       [-1, 32, 16, 16, 16]         110,592\n",
      "     _DenseLayer-134      [-1, 512, 16, 16, 16]               0\n",
      "     BatchNorm3d-135      [-1, 512, 16, 16, 16]           1,024\n",
      "            ReLU-136      [-1, 512, 16, 16, 16]               0\n",
      "          Conv3d-137      [-1, 256, 16, 16, 16]         131,072\n",
      "       AvgPool3d-138         [-1, 256, 8, 8, 8]               0\n",
      "     BatchNorm3d-139         [-1, 256, 8, 8, 8]             512\n",
      "            ReLU-140         [-1, 256, 8, 8, 8]               0\n",
      "          Conv3d-141         [-1, 128, 8, 8, 8]          32,768\n",
      "     BatchNorm3d-142         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-143         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-144          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-145         [-1, 288, 8, 8, 8]               0\n",
      "     BatchNorm3d-146         [-1, 288, 8, 8, 8]             576\n",
      "            ReLU-147         [-1, 288, 8, 8, 8]               0\n",
      "          Conv3d-148         [-1, 128, 8, 8, 8]          36,864\n",
      "     BatchNorm3d-149         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-150         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-151          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-152         [-1, 320, 8, 8, 8]               0\n",
      "     BatchNorm3d-153         [-1, 320, 8, 8, 8]             640\n",
      "            ReLU-154         [-1, 320, 8, 8, 8]               0\n",
      "          Conv3d-155         [-1, 128, 8, 8, 8]          40,960\n",
      "     BatchNorm3d-156         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-157         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-158          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-159         [-1, 352, 8, 8, 8]               0\n",
      "     BatchNorm3d-160         [-1, 352, 8, 8, 8]             704\n",
      "            ReLU-161         [-1, 352, 8, 8, 8]               0\n",
      "          Conv3d-162         [-1, 128, 8, 8, 8]          45,056\n",
      "     BatchNorm3d-163         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-164         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-165          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-166         [-1, 384, 8, 8, 8]               0\n",
      "     BatchNorm3d-167         [-1, 384, 8, 8, 8]             768\n",
      "            ReLU-168         [-1, 384, 8, 8, 8]               0\n",
      "          Conv3d-169         [-1, 128, 8, 8, 8]          49,152\n",
      "     BatchNorm3d-170         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-171         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-172          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-173         [-1, 416, 8, 8, 8]               0\n",
      "     BatchNorm3d-174         [-1, 416, 8, 8, 8]             832\n",
      "            ReLU-175         [-1, 416, 8, 8, 8]               0\n",
      "          Conv3d-176         [-1, 128, 8, 8, 8]          53,248\n",
      "     BatchNorm3d-177         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-178         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-179          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-180         [-1, 448, 8, 8, 8]               0\n",
      "     BatchNorm3d-181         [-1, 448, 8, 8, 8]             896\n",
      "            ReLU-182         [-1, 448, 8, 8, 8]               0\n",
      "          Conv3d-183         [-1, 128, 8, 8, 8]          57,344\n",
      "     BatchNorm3d-184         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-185         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-186          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-187         [-1, 480, 8, 8, 8]               0\n",
      "     BatchNorm3d-188         [-1, 480, 8, 8, 8]             960\n",
      "            ReLU-189         [-1, 480, 8, 8, 8]               0\n",
      "          Conv3d-190         [-1, 128, 8, 8, 8]          61,440\n",
      "     BatchNorm3d-191         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-192         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-193          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-194         [-1, 512, 8, 8, 8]               0\n",
      "     BatchNorm3d-195         [-1, 512, 8, 8, 8]           1,024\n",
      "            ReLU-196         [-1, 512, 8, 8, 8]               0\n",
      "          Conv3d-197         [-1, 128, 8, 8, 8]          65,536\n",
      "     BatchNorm3d-198         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-199         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-200          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-201         [-1, 544, 8, 8, 8]               0\n",
      "     BatchNorm3d-202         [-1, 544, 8, 8, 8]           1,088\n",
      "            ReLU-203         [-1, 544, 8, 8, 8]               0\n",
      "          Conv3d-204         [-1, 128, 8, 8, 8]          69,632\n",
      "     BatchNorm3d-205         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-206         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-207          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-208         [-1, 576, 8, 8, 8]               0\n",
      "     BatchNorm3d-209         [-1, 576, 8, 8, 8]           1,152\n",
      "            ReLU-210         [-1, 576, 8, 8, 8]               0\n",
      "          Conv3d-211         [-1, 128, 8, 8, 8]          73,728\n",
      "     BatchNorm3d-212         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-213         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-214          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-215         [-1, 608, 8, 8, 8]               0\n",
      "     BatchNorm3d-216         [-1, 608, 8, 8, 8]           1,216\n",
      "            ReLU-217         [-1, 608, 8, 8, 8]               0\n",
      "          Conv3d-218         [-1, 128, 8, 8, 8]          77,824\n",
      "     BatchNorm3d-219         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-220         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-221          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-222         [-1, 640, 8, 8, 8]               0\n",
      "     BatchNorm3d-223         [-1, 640, 8, 8, 8]           1,280\n",
      "            ReLU-224         [-1, 640, 8, 8, 8]               0\n",
      "          Conv3d-225         [-1, 128, 8, 8, 8]          81,920\n",
      "     BatchNorm3d-226         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-227         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-228          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-229         [-1, 672, 8, 8, 8]               0\n",
      "     BatchNorm3d-230         [-1, 672, 8, 8, 8]           1,344\n",
      "            ReLU-231         [-1, 672, 8, 8, 8]               0\n",
      "          Conv3d-232         [-1, 128, 8, 8, 8]          86,016\n",
      "     BatchNorm3d-233         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-234         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-235          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-236         [-1, 704, 8, 8, 8]               0\n",
      "     BatchNorm3d-237         [-1, 704, 8, 8, 8]           1,408\n",
      "            ReLU-238         [-1, 704, 8, 8, 8]               0\n",
      "          Conv3d-239         [-1, 128, 8, 8, 8]          90,112\n",
      "     BatchNorm3d-240         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-241         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-242          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-243         [-1, 736, 8, 8, 8]               0\n",
      "     BatchNorm3d-244         [-1, 736, 8, 8, 8]           1,472\n",
      "            ReLU-245         [-1, 736, 8, 8, 8]               0\n",
      "          Conv3d-246         [-1, 128, 8, 8, 8]          94,208\n",
      "     BatchNorm3d-247         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-248         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-249          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-250         [-1, 768, 8, 8, 8]               0\n",
      "     BatchNorm3d-251         [-1, 768, 8, 8, 8]           1,536\n",
      "            ReLU-252         [-1, 768, 8, 8, 8]               0\n",
      "          Conv3d-253         [-1, 128, 8, 8, 8]          98,304\n",
      "     BatchNorm3d-254         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-255         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-256          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-257         [-1, 800, 8, 8, 8]               0\n",
      "     BatchNorm3d-258         [-1, 800, 8, 8, 8]           1,600\n",
      "            ReLU-259         [-1, 800, 8, 8, 8]               0\n",
      "          Conv3d-260         [-1, 128, 8, 8, 8]         102,400\n",
      "     BatchNorm3d-261         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-262         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-263          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-264         [-1, 832, 8, 8, 8]               0\n",
      "     BatchNorm3d-265         [-1, 832, 8, 8, 8]           1,664\n",
      "            ReLU-266         [-1, 832, 8, 8, 8]               0\n",
      "          Conv3d-267         [-1, 128, 8, 8, 8]         106,496\n",
      "     BatchNorm3d-268         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-269         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-270          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-271         [-1, 864, 8, 8, 8]               0\n",
      "     BatchNorm3d-272         [-1, 864, 8, 8, 8]           1,728\n",
      "            ReLU-273         [-1, 864, 8, 8, 8]               0\n",
      "          Conv3d-274         [-1, 128, 8, 8, 8]         110,592\n",
      "     BatchNorm3d-275         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-276         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-277          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-278         [-1, 896, 8, 8, 8]               0\n",
      "     BatchNorm3d-279         [-1, 896, 8, 8, 8]           1,792\n",
      "            ReLU-280         [-1, 896, 8, 8, 8]               0\n",
      "          Conv3d-281         [-1, 128, 8, 8, 8]         114,688\n",
      "     BatchNorm3d-282         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-283         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-284          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-285         [-1, 928, 8, 8, 8]               0\n",
      "     BatchNorm3d-286         [-1, 928, 8, 8, 8]           1,856\n",
      "            ReLU-287         [-1, 928, 8, 8, 8]               0\n",
      "          Conv3d-288         [-1, 128, 8, 8, 8]         118,784\n",
      "     BatchNorm3d-289         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-290         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-291          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-292         [-1, 960, 8, 8, 8]               0\n",
      "     BatchNorm3d-293         [-1, 960, 8, 8, 8]           1,920\n",
      "            ReLU-294         [-1, 960, 8, 8, 8]               0\n",
      "          Conv3d-295         [-1, 128, 8, 8, 8]         122,880\n",
      "     BatchNorm3d-296         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-297         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-298          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-299         [-1, 992, 8, 8, 8]               0\n",
      "     BatchNorm3d-300         [-1, 992, 8, 8, 8]           1,984\n",
      "            ReLU-301         [-1, 992, 8, 8, 8]               0\n",
      "          Conv3d-302         [-1, 128, 8, 8, 8]         126,976\n",
      "     BatchNorm3d-303         [-1, 128, 8, 8, 8]             256\n",
      "            ReLU-304         [-1, 128, 8, 8, 8]               0\n",
      "          Conv3d-305          [-1, 32, 8, 8, 8]         110,592\n",
      "     _DenseLayer-306        [-1, 1024, 8, 8, 8]               0\n",
      "     BatchNorm3d-307        [-1, 1024, 8, 8, 8]           2,048\n",
      "            ReLU-308        [-1, 1024, 8, 8, 8]               0\n",
      "          Conv3d-309         [-1, 512, 8, 8, 8]         524,288\n",
      "       AvgPool3d-310         [-1, 512, 4, 4, 4]               0\n",
      "     BatchNorm3d-311         [-1, 512, 4, 4, 4]           1,024\n",
      "            ReLU-312         [-1, 512, 4, 4, 4]               0\n",
      "          Conv3d-313         [-1, 128, 4, 4, 4]          65,536\n",
      "     BatchNorm3d-314         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-315         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-316          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-317         [-1, 544, 4, 4, 4]               0\n",
      "     BatchNorm3d-318         [-1, 544, 4, 4, 4]           1,088\n",
      "            ReLU-319         [-1, 544, 4, 4, 4]               0\n",
      "          Conv3d-320         [-1, 128, 4, 4, 4]          69,632\n",
      "     BatchNorm3d-321         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-322         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-323          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-324         [-1, 576, 4, 4, 4]               0\n",
      "     BatchNorm3d-325         [-1, 576, 4, 4, 4]           1,152\n",
      "            ReLU-326         [-1, 576, 4, 4, 4]               0\n",
      "          Conv3d-327         [-1, 128, 4, 4, 4]          73,728\n",
      "     BatchNorm3d-328         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-329         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-330          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-331         [-1, 608, 4, 4, 4]               0\n",
      "     BatchNorm3d-332         [-1, 608, 4, 4, 4]           1,216\n",
      "            ReLU-333         [-1, 608, 4, 4, 4]               0\n",
      "          Conv3d-334         [-1, 128, 4, 4, 4]          77,824\n",
      "     BatchNorm3d-335         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-336         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-337          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-338         [-1, 640, 4, 4, 4]               0\n",
      "     BatchNorm3d-339         [-1, 640, 4, 4, 4]           1,280\n",
      "            ReLU-340         [-1, 640, 4, 4, 4]               0\n",
      "          Conv3d-341         [-1, 128, 4, 4, 4]          81,920\n",
      "     BatchNorm3d-342         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-343         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-344          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-345         [-1, 672, 4, 4, 4]               0\n",
      "     BatchNorm3d-346         [-1, 672, 4, 4, 4]           1,344\n",
      "            ReLU-347         [-1, 672, 4, 4, 4]               0\n",
      "          Conv3d-348         [-1, 128, 4, 4, 4]          86,016\n",
      "     BatchNorm3d-349         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-350         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-351          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-352         [-1, 704, 4, 4, 4]               0\n",
      "     BatchNorm3d-353         [-1, 704, 4, 4, 4]           1,408\n",
      "            ReLU-354         [-1, 704, 4, 4, 4]               0\n",
      "          Conv3d-355         [-1, 128, 4, 4, 4]          90,112\n",
      "     BatchNorm3d-356         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-357         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-358          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-359         [-1, 736, 4, 4, 4]               0\n",
      "     BatchNorm3d-360         [-1, 736, 4, 4, 4]           1,472\n",
      "            ReLU-361         [-1, 736, 4, 4, 4]               0\n",
      "          Conv3d-362         [-1, 128, 4, 4, 4]          94,208\n",
      "     BatchNorm3d-363         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-364         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-365          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-366         [-1, 768, 4, 4, 4]               0\n",
      "     BatchNorm3d-367         [-1, 768, 4, 4, 4]           1,536\n",
      "            ReLU-368         [-1, 768, 4, 4, 4]               0\n",
      "          Conv3d-369         [-1, 128, 4, 4, 4]          98,304\n",
      "     BatchNorm3d-370         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-371         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-372          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-373         [-1, 800, 4, 4, 4]               0\n",
      "     BatchNorm3d-374         [-1, 800, 4, 4, 4]           1,600\n",
      "            ReLU-375         [-1, 800, 4, 4, 4]               0\n",
      "          Conv3d-376         [-1, 128, 4, 4, 4]         102,400\n",
      "     BatchNorm3d-377         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-378         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-379          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-380         [-1, 832, 4, 4, 4]               0\n",
      "     BatchNorm3d-381         [-1, 832, 4, 4, 4]           1,664\n",
      "            ReLU-382         [-1, 832, 4, 4, 4]               0\n",
      "          Conv3d-383         [-1, 128, 4, 4, 4]         106,496\n",
      "     BatchNorm3d-384         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-385         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-386          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-387         [-1, 864, 4, 4, 4]               0\n",
      "     BatchNorm3d-388         [-1, 864, 4, 4, 4]           1,728\n",
      "            ReLU-389         [-1, 864, 4, 4, 4]               0\n",
      "          Conv3d-390         [-1, 128, 4, 4, 4]         110,592\n",
      "     BatchNorm3d-391         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-392         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-393          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-394         [-1, 896, 4, 4, 4]               0\n",
      "     BatchNorm3d-395         [-1, 896, 4, 4, 4]           1,792\n",
      "            ReLU-396         [-1, 896, 4, 4, 4]               0\n",
      "          Conv3d-397         [-1, 128, 4, 4, 4]         114,688\n",
      "     BatchNorm3d-398         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-399         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-400          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-401         [-1, 928, 4, 4, 4]               0\n",
      "     BatchNorm3d-402         [-1, 928, 4, 4, 4]           1,856\n",
      "            ReLU-403         [-1, 928, 4, 4, 4]               0\n",
      "          Conv3d-404         [-1, 128, 4, 4, 4]         118,784\n",
      "     BatchNorm3d-405         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-406         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-407          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-408         [-1, 960, 4, 4, 4]               0\n",
      "     BatchNorm3d-409         [-1, 960, 4, 4, 4]           1,920\n",
      "            ReLU-410         [-1, 960, 4, 4, 4]               0\n",
      "          Conv3d-411         [-1, 128, 4, 4, 4]         122,880\n",
      "     BatchNorm3d-412         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-413         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-414          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-415         [-1, 992, 4, 4, 4]               0\n",
      "     BatchNorm3d-416         [-1, 992, 4, 4, 4]           1,984\n",
      "            ReLU-417         [-1, 992, 4, 4, 4]               0\n",
      "          Conv3d-418         [-1, 128, 4, 4, 4]         126,976\n",
      "     BatchNorm3d-419         [-1, 128, 4, 4, 4]             256\n",
      "            ReLU-420         [-1, 128, 4, 4, 4]               0\n",
      "          Conv3d-421          [-1, 32, 4, 4, 4]         110,592\n",
      "     _DenseLayer-422        [-1, 1024, 4, 4, 4]               0\n",
      "     BatchNorm3d-423        [-1, 1024, 4, 4, 4]           2,048\n",
      "            ReLU-424        [-1, 1024, 4, 4, 4]               0\n",
      "AdaptiveAvgPool3d-425        [-1, 1024, 1, 1, 1]               0\n",
      "         Flatten-426                 [-1, 1024]               0\n",
      "          Linear-427                    [-1, 2]           2,050\n",
      "================================================================\n",
      "Total params: 11,244,674\n",
      "Trainable params: 11,244,674\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 8.00\n",
      "Forward/backward pass size (MB): 2684.89\n",
      "Params size (MB): 42.90\n",
      "Estimated Total Size (MB): 2735.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(1,128,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0809, 0.3521]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn((1, 1, 64, 64, 64)).cuda()\n",
    "output2 = model(inputs)\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
